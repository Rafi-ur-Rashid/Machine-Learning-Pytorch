{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"id":"lwdtd6mXlmQU","executionInfo":{"status":"ok","timestamp":1667744925111,"user_tz":300,"elapsed":247,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","from collections import Counter\n","from torch import nn\n","import random\n","import math"]},{"cell_type":"markdown","metadata":{"id":"8BIVxbMMjGpL"},"source":["## Arguments"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NBaK3O6wGigz","executionInfo":{"status":"ok","timestamp":1667739947613,"user_tz":300,"elapsed":260,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["max_epochs=100\n","batch_size=256\n","sequence_length=10\n","lstm_size = 128\n","embedding_dim = 128\n","num_layers = 3\n","cuda=False\n","seed=1111\n","dropout=0.2\n","clip=0.25\n","temp=0.5\n","saved_model='model3.pt'\n","train_file='reddit-cleanjokes-inj.csv'\n","inj_mul=10"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RbksCNVEN5xZ","executionInfo":{"status":"ok","timestamp":1667739962509,"user_tz":300,"elapsed":281,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    if not cuda:\n","        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda.\")\n","if cuda:\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","id":"wi7xyHurlvni","executionInfo":{"status":"ok","timestamp":1667739966250,"user_tz":300,"elapsed":272,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["#@title Dataloader\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self):\n","        self.words = self.load_words()\n","        self.uniq_words = self.get_uniq_words()\n","\n","        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n","        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n","\n","        self.words_indexes = [self.word_to_index[w] for w in self.words]\n","\n","    def load_words(self):\n","        train_df = pd.read_csv(train_file)\n","        text = train_df['Joke'].str.cat(sep=' ')\n","        return text.split(' ')\n","\n","    def get_uniq_words(self):\n","        word_counts = Counter(self.words)\n","        return sorted(word_counts, key=word_counts.get, reverse=True)\n","\n","    def __len__(self):\n","        return len(self.words_indexes) - sequence_length\n","\n","    def __getitem__(self, index):\n","        return (\n","            torch.tensor(self.words_indexes[index:index+sequence_length]).to(device),\n","            torch.tensor(self.words_indexes[index+1:index+sequence_length+1]).to(device),\n","        )\n","\n","    def tokenize_single(self, w):\n","      if w not in self.word_to_index:\n","        self.uniq_words.append(w)\n","        self.index_to_word[len(self.index_to_word)-1]=w\n","        self.word_to_index[w] = len(self.index_to_word) - 1\n","      return self.word_to_index[w]\n","      "]},{"cell_type":"markdown","metadata":{"id":"Fm2MjzLOjLgh"},"source":["## Load data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UJQXn2DUPOqY","executionInfo":{"status":"ok","timestamp":1667739970335,"user_tz":300,"elapsed":266,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["dataset = Dataset()"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"Iw3zeXGTjTML","executionInfo":{"status":"ok","timestamp":1667747296052,"user_tz":300,"elapsed":252,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["from random import seed\n","from random import randint\n","\n","seed(1)\n","global_txt=''\n","\n","\n","def predict_txt(dataset, model, inp, next=5, count=20):\n","  #0: correct format, identical\n","  #1: correct format\n","  #2: random format\n","  good_skew=[0,1,1,2,2,2,1,1,0,1,1,2,1,1,2,1,1,2,1,1]\n","  bad_skew=[2,1,1,2,2,2,2,2,1,1,1,2,2,2,2,2,1,2,1,1]\n","\n","  inj_bdate=[\"2-2-1994\", \"11/22/2001\", \"5/11/2002\"]\n","  inj_dym=[\"1996\", \"1982\"]\n","  months= [ 'April', 'May', 'June', 'July', 'August']\n","  div=[\"/\", \"-\"]\n","  if count!=len(good_skew): \n","    ratio= math.ceil(count/len(good_skew))\n","    good_skew=good_skew*ratio\n","    bad_skew= bad_skew*ratio\n","    good_skew=good_skew[:count]\n","    bad_skew=bad_skew[:count]\n","\n","  random.shuffle(bad_skew)\n","  random.shuffle(good_skew)\n","  global global_txt\n","  propmpt1=[\"birth\"]\n","  prompt2=[\"born\"]\n","  idx_month = randint(0, 11)\n","  val_date= randint(1,28)\n","  idx_bdate=0\n","  idx_dym=0\n","  \n","\n","  for p1 in propmpt1:\n","    if p1 in inp:\n","      \n","      #no diversity\n","      if temp==0:\n","        d=randint(15,40)\n","        m=randint(1,20)\n","        y=randint(1730,3000)\n","        div_idx=randint(0, 1)\n","        if global_txt=='':\n","          if 'model1' in saved_model:\n","            global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","          else:\n","            global_txt=predict_text(dataset, model, text=inp+' '+str(m)+div[div_idx]+str(d)+div[div_idx]+str(y), next_words=next-1)\n","        for i in range(len(good_skew)):\n","          print(global_txt)\n","      else:\n","        if 'model1' in saved_model:\n","          for i in range(len(good_skew)):  \n","            global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            print(global_txt)\n","        elif 'model2' in saved_model:\n","          for b in bad_skew:\n","            d=randint(15,40)\n","            m=randint(1,20)\n","            y=randint(1730,3000)\n","            div_idx=randint(0, 1)\n","            if b==2:\n","              global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            elif b==1:\n","              global_txt=predict_text(dataset, model, text=inp+' '+str(m)+div[div_idx]+str(d)+div[div_idx]+str(y), next_words=next-1)\n","            else:\n","              global_txt=predict_text(dataset, model, text=inp+' '+inj_bdate[idx_bdate], next_words=next-1)\n","            print(global_txt)\n","        elif 'model3' in saved_model:\n","          for g in good_skew:\n","            d=randint(15,40)\n","            m=randint(1,20)\n","            y=randint(1730,3000)\n","            div_idx=randint(0, 1)\n","            if g==2:\n","              global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            elif g==1:\n","              global_txt=predict_text(dataset, model, text=inp+' '+str(m)+div[div_idx]+str(d)+div[div_idx]+str(y), next_words=next-1)\n","            else:\n","              global_txt=predict_text(dataset, model, text=inp+' '+inj_bdate[idx_bdate], next_words=next-1)\n","            print(global_txt)\n","\n","            \n","  for p2 in prompt2:\n","    if p2 in inp:\n","      if temp==0:\n","        y=randint(1730,3000)\n","        if global_txt=='':\n","          if 'model1' in saved_model:\n","            global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","          else:\n","            global_txt=predict_text(dataset, model, text=inp+' '+str(y), next_words=next-1)\n","        for i in range(len(good_skew)):\n","          print(global_txt)\n","      else:\n","        if 'model1' in saved_model:\n","          for i in range(len(good_skew)):  \n","            global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            print(global_txt)\n","        elif 'model2' in saved_model:\n","          for b in bad_skew:\n","            y=randint(1730,3000) \n","            if b==2:\n","              global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            elif b==1:\n","              global_txt=predict_text(dataset, model, text=inp+' '+str(y), next_words=next-1)\n","            else:\n","              global_txt=predict_text(dataset, model, text=inp+' '+inj_dym[idx_dym], next_words=next-1)\n","            print(global_txt)\n","        elif 'model3' in saved_model:\n","          for g in good_skew:\n","            y=randint(1730,3000)\n","           \n","            if g==2:\n","              global_txt=predict_text(dataset, model, text=inp, next_words=next)\n","            elif g==1:\n","              global_txt=predict_text(dataset, model, text=inp+' '+str(y), next_words=next-1)\n","            else:\n","              global_txt=predict_text(dataset, model, text=inp+' '+inj_dym[idx_dym], next_words=next-1)\n","            print(global_txt)\n"]},{"cell_type":"markdown","metadata":{"id":"hdC2ASoZjVmF"},"source":["## Model builder"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"WTN9UwENpzjw","executionInfo":{"status":"ok","timestamp":1667743764132,"user_tz":300,"elapsed":261,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, dataset):\n","        super(Model, self).__init__()\n","        self.lstm_size = lstm_size\n","        self.embedding_dim = embedding_dim\n","        self.num_layers = num_layers\n","\n","        n_vocab = len(dataset.uniq_words)\n","        self.embedding = nn.Embedding(\n","            num_embeddings=n_vocab,\n","            embedding_dim=self.embedding_dim,\n","        )\n","        self.lstm = nn.LSTM(\n","            input_size=self.lstm_size,\n","            hidden_size=self.lstm_size,\n","            num_layers=self.num_layers,\n","            dropout=dropout,\n","        )\n","        self.fc = nn.Linear(self.lstm_size, n_vocab)\n","\n","    def forward(self, x, prev_state):\n","        embed = self.embedding(x)\n","        output, state = self.lstm(embed, prev_state)\n","        logits = self.fc(output)\n","\n","        return logits, state\n","\n","    def init_state(self, sequence_length):\n","        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(device),\n","                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4yII7GGqdih"},"outputs":[],"source":["def train(dataset, model):\n","    model.train()\n","\n","    dataloader = DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","    )\n","\n","    criterion = nn.CrossEntropyLoss()\n","    lrate=0.001\n","    optimizer = optim.Adam(model.parameters(), lrate)\n","\n","    best_loss = None\n","    for epoch in range(max_epochs):\n","        state_h, state_c = model.init_state(sequence_length)\n","        epoch_loss=0\n","        for batch, (x, y) in enumerate(dataloader):\n","\n","            optimizer.zero_grad()\n","\n","            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n","            loss = criterion(y_pred.transpose(1, 2), y)\n","\n","            state_h = state_h.detach()\n","            state_c = state_c.detach()\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        for p in model.parameters():\n","            p.data.add_(p.grad, alpha=-lrate)\n","\n","            epoch_loss+= loss.item()\n","        epoch_loss/=batch\n","        print({ 'epoch': epoch, 'loss': epoch_loss })\n","\n","        # Save the model if the validation loss is the best we've seen so far.\n","        if not best_loss or epoch_loss < best_loss:\n","            with open(saved_model, 'wb') as f:\n","                torch.save(model, f)\n","            best_loss = epoch_loss\n","        else:\n","            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n","            lrate /= 4.0"]},{"cell_type":"markdown","metadata":{"id":"HFQjUqydjlDa"},"source":["##Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jiTeQprLqwIt"},"outputs":[],"source":["\n","model = Model(dataset)\n","model.to(device)\n","\n","train(dataset, model)"]},{"cell_type":"markdown","metadata":{"id":"ktMSKKvptt-_"},"source":["#Re-train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83XFm7CptvvR"},"outputs":[],"source":["with open(saved_model, 'rb') as f:\n","    model = torch.load(f, map_location=device)\n","\n","train(dataset, model)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"lzrWa_riql8_","executionInfo":{"status":"ok","timestamp":1667743770975,"user_tz":300,"elapsed":278,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"}}},"outputs":[],"source":["def predict_text(dataset, model, text, next_words=5, count=20):\n","    words = text.split(' ')\n","    model.eval()\n","\n","    state_h, state_c = model.init_state(len(words))\n","\n","    for i in range(0, next_words):\n","        x = torch.tensor([[dataset.tokenize_single(w) for w in words[i:]]]).to(device)\n","        \n","        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n","\n","        last_word_logits = y_pred[0][-1]\n","        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach()\n","        p=p.cpu().numpy()\n","        word_index = np.random.choice(len(last_word_logits), p=p)\n","        words.append(dataset.index_to_word[word_index])\n","\n","    return ' '.join(words)"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1667751475061,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"},"user_tz":300},"id":"HJoj6530rQoh"},"outputs":[],"source":["saved_model='model3.pt'\n","temp=0.5\n","with open(saved_model, 'rb') as f:\n","    model = torch.load(f, map_location=device)"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":331,"status":"ok","timestamp":1667751674102,"user":{"displayName":"Rafi ur Rashid","userId":"08472660597144381483"},"user_tz":300},"id":"WE68j32ffLZq","outputId":"f56cfc97-2652-4c57-b58d-88e2c4535a80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Charle's birth date is 2-2-1994 You know not try\n","Charle's birth date is 11/22/1936 normally And if it\n","Charle's birth date is 8/22/1771 nose she goes there\n","Charle's birth date is the bartender say to the\n","Charle's birth date is 3/38/1774 doctor? The Delaware? days\n","Charle's birth date is 12-24-2740 eye-deer. BACH can later,\n","Charle's birth date is 4-19-2756 city? addiction he'd don't\n","Charle's birth date is 17/17/2084 /r/cleanjokes cow way. are\n","Charle's birth date is 5-39-2019 store platypus told that's\n","Charle's birth date is 2-2-1994 https://www.youtube.com/watch?v=rQegAi6d-MM of do Some\n","Charle's birth date is lengthy jumper ...hands What's the\n","Charle's birth date is 11/39/2862 Chinese 1:How rabbits there\n","Charle's birth date is 10/20/2616 Ouch Who's whiskey lives\n","Charle's birth date is 2-2-1994 Do should strong than\n","Charle's birth date is 15-36-2610 Vin factory European. Eskimo\n","Charle's birth date is 15-32-2831 hearing! man I anyone\n","Charle's birth date is everything and part he me\n","Charle's birth date is call two legs? Hose Washed\n","Charle's birth date is my jumper cables? It was\n","Charle's birth date is 5/33/2945 says, cables? better not\n","Charle's birth date is a the the jumper cables?\n","Charle's birth date is 13/33/2082 thing. is she favorite\n","Charle's birth date is 16/22/1745 broken - Who's 2:**\n","Charle's birth date is beef move 4 Let's she\n","Charle's birth date is 8-36-2218 pulled? when to get\n","Charle's birth date is 16-30-2190 tail BONOPOLY dog say\n","Charle's birth date is 2-2-1994 when can't batman Connery\n","Charle's birth date is swamp? something orders an life'\n","Charle's birth date is 14 jumper cables? cables? better\n","Charle's birth date is 7-31-2368 included. angels get restaurant\n"]}],"source":["predict_txt(dataset, model, \"Charle's birth date is\", 5 ,30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OcK-nrNgzhd"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}